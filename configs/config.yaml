seed: 42
dataset_name: "openai/gsm8k"
model_name: "Qwen/Qwen2.5-0.5B"

# data split ratios
split_ratios:
  sft: 0.8
  rl: 0.1
  val: 0.1

# prompt + CoT length
max_length: 512

# training hyperparams
learning_rate: 2e-5
batch_size: 8
grad_accum_steps: 4
num_epochs: 3
weight_decay: 0.01
warmup_steps: 100

# num workers for data loading
num_workers: 4

# output dirs
sft_output_dir: "sft_checkpoint"
ppo_output_dir: "ppo_checkpoint"
grpo_output_dir: "grpo_checkpoint"